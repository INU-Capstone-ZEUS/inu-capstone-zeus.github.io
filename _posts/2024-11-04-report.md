---
title: 주간 보고서(10.28~11.03)
tags: TeXt
sidebar:
  nav: docs-ko
aside:
  toc: true
lang: ko
---


---

## 업무요약

<aside>
<img src="https://www.notion.so/icons/light-bulb_yellow.svg" alt="https://www.notion.so/icons/light-bulb_yellow.svg" width="40px" />

</aside>

- 박종현 : 학습 루프 제작 및 딥러닝 모델 성능 실험 진행
- 이제욱 :  S3, EC2 설정 및 FastAPI S3 업로드 테스트
- 조민수 :  키움증권 로그인 및 종목 데이터 받아오기 구현 및 32bit/64bit 환경 연결 시도
- 조하은 :  프론트 제작 및 크롤링 서버 배포(Docker), MockAPI를 통한 테스트 환경 구축


---


# 세부 업무 내용

# (종현)

## 라벨 분포 시간대 확인

![image.png](https://github.com/INU-Capstone-ZEUS/inu-capstone-zeus.github.io/blob/master/assets/images/report/_9_report/image.png?raw=true)

 클래스 불균형을 고려하여 반등과 하락 비율이 적절한 지점을 찾기 위하여 시간대에 따른 반등 빈도를 확인하였다. 9시~9시 30분 동안 특히 많은 급등이 포착되었으나, 이는 애초에 종목 선정을 9시 30분 이전에 급등한 종목만을 추출했기 때문으로 보인다. 따라서 9시 30분 이후에 반등이 주로 일어나는 시간대의 빈도를 확인하였을 때(그림 2), 시간이 지남에 따라 반등하는 경우가 적어짐을 확인할 수 있었다.

 따라서 반등 빈도가 현저히 적은 1시 이후를 학습 데이터에서 제외하고, 오전 9시 ~ 오후 1시까지 총 4시간의 데이터를 별도의 데이터셋(AM)으로 생성하여 기존 데이터셋(All)과 비교하여 학습을 진행하였다.

---

## 실험 환경 구성

### 공통 조건

- 최적화 : Adam(weigth decay 1e-4)
- 학습률 : 0.001
- Batch Size 32
- Epochs 100
- 학습률 스케줄링 미사용
- EarlyStopping 사용
- train 데이터셋 80%, 테스트 데이터셋 20% 사용
- Random Seed 42로 고정
- 조건식 A만 진행

### 1. 모델 구성

 실시간으로 주가를 입력받고 빠르게 매수 판단을 내려야하기 때문에 가능한 트랜스포머 모델을 제외하여 가벼운 모델부터 우선하여 실험하였다. 실험 모델은 아래와 같다.

- **LSTM-FCN 모델**

 RNN계열의 대표주자인 LSTM와 Linear레이어를 결합하여 만든 모델로, Paper With Code에서 Time Series Classification 분야에 상위 랭크에 존재하는 모델이다. 트랜스포머에 비해 비교적 가볍다는 이점이 분명하여 채택하였다. 다만 과적합을 고려하여 LSTM와 Linear 사이에 30% 비율의 Dropout을 적용하였다.

- **Dlinear 모델**

![image.png](https://github.com/INU-Capstone-ZEUS/inu-capstone-zeus.github.io/blob/master/assets/images/report/_9_report/image%201.png?raw=true)

 Dlinear는 **Are Transformers Effective for Time Series Forecasting? (zeng et al., 2022)에서** 소개된 모델로, 간단한 1-Layer Linear Network를 사용하는 모델이다. 입력 시퀀스(Look bcak Window)를 시계열 분해를 통해 추세(Trend)와 나머지(Remainder)을 추출해내고, 이를 각각의 선형 네트워크에 입력하여 예측 결과를 합치는 것을 말한다. 정말 가볍고 간단한 모델이지만 LTSF(Long time Series Forecasting)에서 트랜스포머를 뛰어넘는 성능까지 증명되어 적용해보았다.

 추가적으로, Multivariate Input일 경우에 변수 간 Linear 레이어를 공유하는 Dlinear-S와, 변수별로 각기 다른 Linear 레이어를 가지는 Dlinear-I가 존재한다. 본 실험에서는 주가 뿐만 아니라 거래대금 및 다양한 기술지표들을 입력 변수로 삼기 때문에 Dlinear-S와 Dlinear-I 모두 실험을 진행하였다.

### 2. 데이터셋 구성

 두가지 데이터셋 종류로 나눠서 실험했으며, 각 데이터셋 모두 사이즈 10의 슬라이딩 윈도우를 적용한 윈도우 시퀀스로 구성되어 있다.

- **종일 데이터셋(All)**

 위에서 설명한대로 수집된 모든 시간대에 속하는 데이터를 입력 시퀀스로 변환한 데이터셋이다.

- **오전 데이터셋(AM)**

 마찬가지로 오후 1시까지의 데이터를 입력 시퀀스로 변환한 데이터셋이다.

### 3. Feature 구성

- 10 feature - 주가(시가, 종가,고가,저가), 거래대금 및 추가 기술지표를 종합한 10가지 지표
- 13 feature - 주가(시가, 종가,고가,저가), 거래대금 및 추가 기술지표를 종합한 13가지 지표

### 4. 손실 함수

- Cross Entropy Loss func
- Focal Loss func(Cross Entropy)

## 실험 결과

 위에서 설명한 모델 구조, 데이터셋 종류, Feature 구성, 손실 함수를 변경해가며 Training Loss와 Valid Loss의 변화(좌측), Valid Dateset의 Precision(True로 분류한 정확도)의 변화(우측)를 Plotting하여 기록하였다. 또한 학습 도중 에폭마다 Loss와 Precision을 텍스트 파일로 기록해두었다(하단 그림).

![image.png](https://github.com/INU-Capstone-ZEUS/inu-capstone-zeus.github.io/blob/master/assets/images/report/_9_report/image%202.png?raw=true)

![image.png](https://github.com/INU-Capstone-ZEUS/inu-capstone-zeus.github.io/blob/master/assets/images/report/_9_report/image%203.png?raw=true)

### 실험 결과 정리

 실험한 결과를 표로 정리하였다. 분류 모델이 반등 패턴으로 분류한 것의 정확도를 기재하였으며, 학습 과정중 최고 정확도(**Best Precision**)와 마지막 10에폭 동안의 평균 정확도(**Last 10 Average Precision**), 그리고 마지막 에폭의 정확도(**Final Precision**)를 기재하였다.

 실험 결과로 13개의 변수를 입력으로 사용한 LSTM-FCN이 All 데이터셋과 AM 데이터셋 모두에서 가장 높은 성능을 보여줬고, 특히 BCE 손실함수를 사용했을 때 가장 높은 정확도를 기록하였다.

|  |  |  | LSTM-FCN |  | Dlinear-S |  | Dlinear_I |  |
| --- | --- | --- | --- | --- | --- | --- | --- | --- |
|  |  |  | **10 Features** | **13 Features** | **10 Features** | **13 Features** | **10 Features** | **13 Features** |
| **All Dataset** | **BCE** | **Best Precision** | 53.87% | **63.10%** | 10.40% | 13.06% | 10.48% | 16.18% |
|  |  | **Last 10 Average Precision** | 50.31% | **57.40%** | 7.24% | 10.85% | 6.65% | 9.15% |
|  |  | **Final Precision** | 48.08% | **59.74%** | 7.35% | 10.35% | 8.00% | 10.77% |
|  | **Focal BCE** | **Best Precision** | 53.48% | **55.23%** | 8.44% | 11.68% | 7.15% | 14.82% |
|  |  | **Last 10 Average Precision** | 45.64% | **43.05%** | 6.25% | 9.03% | 4.95% | 7.79% |
|  |  | **Final Precision** | 41.65% | **43.30%** | 6.85% | 8.28% | 5.55% | 9.12% |
| **AM Dataset** | **BCE** | **Best Precision** | 62.22% | **65.45%** | 14.52% | 20.94% | 16.23% | 25.42% |
|  |  | **Last 10 Average Precision** | 58.58% | **61.03%** | 11.60% | 17.04% | 12.03% | 18.08% |
|  |  | **Final Precision** | 61.02% | **61.66%** | 10.38% | 15.37% | 9.76% | 14.77% |
|  | **Focal BCE** | **Best Precision** | 55.27% | **57.87%** | 13.54% | 19.29% | 13.24% | 20.10% |
|  |  | **Last 10 Average Precision** | 49.57% | **49.07%** | 9.90% | 15.25% | 7.94% | 13.23% |
|  |  | **Final Precision** | 54.39% | **49.60%** | 10.10% | 12.56% | 5.26% | 12.35% |

### 추후 실험 계획

 성능 개선을 위해 가장 먼저 또 다른 모델을 대조군으로 실험할 계획이다. 또한 일봉 혹은 5분봉 데이터를 학습에 적용할 수 있는 방법을 연구하여 정확도를 향상시키는데 집중할 계획이다.

---







---

If you like TeXt, don't forget to give me a star. :star2:

[![Star This Project](https://img.shields.io/github/stars/kitian616/jekyll-TeXt-theme.svg?label=Stars&style=social)](https://github.com/kitian616/jekyll-TeXt-theme/)
