---
title: 주간 보고서(10.14~10.20)
tags: TeXt
sidebar:
  nav: docs-ko
aside:
  toc: true
lang: ko
---

---

## 업무요약

<aside>
<img src="https://www.notion.so/icons/light-bulb_yellow.svg" alt="https://www.notion.so/icons/light-bulb_yellow.svg" width="40px" />

</aside>

- 박종현 : 영웅문 데이터 추출, 데이터 전처리 및 라벨링
- 이제욱 :  영웅문 데이터 추출, EC2 OOM 문제 예방(스왑 메모리), 가비아 도메인 구매 및 적용, Nginx 웹 서버 구축 및 SSL 인증서 적용
- 조민수 :  영웅문 데이터 추출
- 조하은 :  Fast API 서버 구축 및 배포


---


# 세부 업무 내용

## 영웅문 데이터 추출

 3개의 방식으로 데이터를 추출하여 모델 학습을 진행할 예정으로 박종현 팀장 조민수 팀원 그리고 이제욱 팀원이 한 방식씩 맡아 데이터 추출을 진행하였다. 키움증권에서 제공하는 영웅문에서 해당 과정을 진행하였으며 4월부터 10월까지 각 검색기 별로 500여개가 넘는 종목을 추출하였다.

![image.png](https://github.com/INU-Capstone-ZEUS/inu-capstone-zeus.github.io/blob/master/assets/images/report/_7_report/image.png?raw=true)


 현재 조민수 팀원이 실제 주가 데이터 추출을 진행 중이며, 양이 방대해 시간이 소요되고 있다.

---

## 데이터 수집 및 전처리 테스트

 팀원들의 도움 덕에 키움증권의 조건검색 노가다를 마치고 종목별 주가 데이터를 추출하였다. 데이터 양이 방대해 조민수 팀원이 추출하는데 오랜 시간이 소요되고 있으며, 아래는 테스트용으로 지난 24년 4월 5일, 주도주 검색기에 검출된 종목들에 대한 전처리와 라벨링을 수행한 결과이다.

- **데이터 전처리 및 라벨링**

![image.png](https://github.com/INU-Capstone-ZEUS/inu-capstone-zeus.github.io/blob/master/assets/images/report/_7_report/image%201.png?raw=true)

검색 시점 전일 2일부터 당일까지 총 3일의 데이터가 포함되어 있음. 장 개장 시간인 평일 9시~ 오후 3시 30분까지 총 362개의 row가 존재하며, 시가, 고가, 종가, 저가 등 “가격”에 대한 정보와, 거개량, 거래대금 등의 “거래금액” 정보가 존재한다.

 아래 그림은 종목코드 “A000440”이 지난 24년 4월 5일 급등했던 주식차트를 그린 것으로, 계획대로 주식의 미래 가격을 예측하는 것이 아닌, 현재 종가를 기준으로 3% 반등에 성공할 경우와 1.5% 하락할 경우를 구분지어 라벨링 하였다.

![image.png](https://github.com/INU-Capstone-ZEUS/inu-capstone-zeus.github.io/blob/master/assets/images/report/_7_report/image%202.png?raw=true)

 위 작업을 기반으로 4월 5일 “주도주 검색기”에서 검색되었던 모든 종목들의 데이터를 전처리 및 기술 지표들을 추가하고, 라벨링을 진행하였다.

![image.png](https://github.com/INU-Capstone-ZEUS/inu-capstone-zeus.github.io/blob/master/assets/images/report/_7_report/image%203.png?raw=true)

- **정상성 문제**

 주가는 추세(Trend)가 존재한다. 장기간동안 주가가 계속해서 상승하는 경우도 있고, 바닥을 기거나 하락하는 경우가 발생한다. 이러한 특성 때문에 주가는 필연적으로 정상성(Stationary)을 만족하지 못하는 문제에 직면하게 된다. 시계열 분석, 그리고 모델 학습과 예측을 위해서는 반드시 정상성을 만족시켜야만 한다.

<aside>
💡

왜 정상성이 중요한가?

 정상성이란, 데이터의 평균과 분산이 **항상** 일정한 것을 말한다. 통계적으로 우리가 추출한 표본 평균이 일정한 평균과 분산을 지니는 정규분포 내에서 존재하는 확률 분포를 따라야만 예측이 가능하다. 마치 가설 검정에서 표본 평균의 분포 어딘가에 존재할 모평균을 검정하는 것과 유사하며, 우리가 수집한 표본(주가 데이터)의 평균 또한 일정한 정규 분포 내에 존재해야만 모수 추정, 즉 예측이 가능해진다. (예측이란 결국 과거의 데이터의 공통된 패턴을 찾는 것. 모수를 벗어난 새로운 값을 창작하는 것이 아니기 때문)

 하지만 시계열 데이터가 일정한 패턴을 가지거나 지속적으로 상승, 하락하게 된다면 어떻게 될까? 데이터의 평균과 분산이 지속적으로 달라지며, 시간이 흐름에 따라 확률 분포가 계속 변하게 되면 과거 데이터의 모멘트가 의미가 없어지기 때문이다. 따라서 우리가 분석하려는 데이터는 일정한 평균과 분산을 가지는 정상성을 만족해야만 한다.

</aside>

 정규성 만족을 위한 방법은 이미 많이 알려져있다. 차분과 로그 변환을 통해 변형을 시킨 뒤에, ACF를 확인하는 등 정규성을 검정하는 방법까지 존재한다. 다만 주가 데이터의 경우 단순 차분이 적합할지는 모르겠다. 종목마다 주식의 가격이 천차만별이기 때문이고, 특히 10만원 단위 이상의 종목같은 경우 호가단위(1천원 or 5천원)는 1천원 단위의 종목의 호가단위(100원 or 50원)와 다르기 때문이다. 뿐만 아니라 실제 매매에 적용하기 위해서는 가격 scaling을 위한 Min-Max Scailing을 적용한 후, 해당 값들을 전부 기억했다가 실제 매매에 적용시켜줘야 하는데, 주가는 계속 변하기 때문에 종목마다 최댓값과 최솟값이 계속해서 변할 수 있어 이를 상시 모니터링해야 한다는 문제가 있다.

 따라서 단순 차분이 아니라 등락률(%)을 이용하는 것도 하나의 방법일 것으로 판단된다. 차분이 없이 Raw 데이터로 학습을 시켜보고, 등락률을 적용한 방안도 테스트할 필요가 있어 보인다. 

## 모델 선정

- **Times Library 이용**

[https://github.com/thuml/Time-Series-Library](https://github.com/thuml/Time-Series-Library)

 시계열 분류를 위해 선정할 모델은 위의 Time Series Library에서 상위 등수로 랭킹을 매긴 TimesNet과 Non-stationary Transformer 등을 적용할 예정이다. 두 모델 모두 사용해본 경험이 있으며, 성능도 1,2 등을 다투기 때문에 고도화된 모델로 선정하기에 적합하다고 판단했다.

- **현재 코드 분석 및 Dataloader 생성 코드 커스터마이징 중**

 Time Series Library가 제공하는 ipynb은 argparse를 사용하는데, 해당 라이브러리는 코랩에서 이용하기 여의치않기 때문에, 객체로 변환해주는 작업을 진행하였다. (예시)

![image.png](https://github.com/INU-Capstone-ZEUS/inu-capstone-zeus.github.io/blob/master/assets/images/report/_7_report/image%204.png?raw=true)

이후 학습을 위해서는, experiement 단에서 Datafactory를 거쳐 Dataloader를 생성하게 된다. 아래 코드는 Datafactory에서 데이터로더 생성을 위해 학습 데이터를 읽고, train, valid, test 용도로 나눈 뒤 timestamp에 대한 전처리가 적용되는 코드이다. 사용하는 데이터가 애초에 다르기 때문에 칼럼과 사이즈를 맞추는 작업을 진행 중이다. 작업이 끝나면 바로 모델 학습 코드를 수정할 예정.

![image.png](https://github.com/INU-Capstone-ZEUS/inu-capstone-zeus.github.io/blob/master/assets/images/report/_7_report/image%205.png?raw=true)

---

## EC2 OOM 문제 예방

 현재 사용하고 있는 인스턴스는 t2.micro이고 현재는 아직 OOM 문제를 발견하지는 못하였으나 서비스들을 완성하고 해당 환경에서 배포를 시작한다면 여러 개의 서비스를 올리는 특성상 OOM 문제를 맞닥뜨릴 것이라고 생각한다. 

<aside>
💡

OOM (Out Of Memory) 인스턴스에서 사용할 수 있는 메모리가 모두 소진되어 더 이상 할당할 수 없는 상태 

</aside>

따라서 사전에 예방책을 준비하기로 하였고 현재는 스왑 메모리를 사용하기로 결정하였다. 스왑 메모리를 사용하더라도 문제가 생긴다면 그때에는 인스턴스 업그레이드를 하기로 한다. 어느 정도의 비용이 발생하겠지만 최대한 비용 효율적으로 결정하겠다. 

### 스왑 메모리 사용

 그렇다면 스왑이란 무엇인가? 스왑은 컴퓨터에서 주메모리가 부족할 때 사용할 수 있는 보조 저장 공간이다. 주메모리는 프로그램에 필요한 데이터를 일시적으로 저장하는데, 가끔 시스템이 필요로 하는 메모리 양이 주메모리 용량을 초과하는 경우가 발생한다. 우리의 경우에는 여러 개의 Docker Container를 띄울 것이니 서비스 과다가 해당할 수 있겠다.

이런 경우, 스왑 메모리는 가상 메모리처럼 사용된다. 주메모리에 저장할 수 없는 데이터를 HDD나 SSD 같은 보조 저장 장치에 저장하여 해결하는 것이다. 이를 스왑 공간이라 부른다. 

AWS 환경에서는 EBS 볼륨을 해당 공간으로 활용한다. 

### 테라폼 코드 수정

 현재 AWS 환경을 테라폼으로 띄우고 있다. 테라폼에서 USER_DATA 필드를 사용하여 시작 시 실행시킬 스크립트 파일을 사용 중에 있다. 

이전에는 Docker service를 받고 실행시키기 위해 사용하였지만, 스왑 메모리 또한 시작하기 위해 스크립트 파일을 수정한다. 

```python
resource "aws_instance" "bastion" {
  ami           = "ami-0ee82191e264e07cc"  # Amazon Linux 2 AMI (region-specific) seoul
  instance_type = "t2.micro"
  subnet_id     = var.subnets_public_ids[0]
  key_name      = "bastion_key"  # SSH key

  vpc_security_group_ids = [aws_security_group.bastion_sg.id]

  user_data = <<-EOF
  #!/bin/bash
  sudo yum update -y
  sudo yum install -y docker
  sudo service docker start
  sudo usermod -a -G docker ec2-user

  sudo timedatectl set-timezone Asia/Seoul

  sudo dd if=/dev/zero of=/swapfile bs=128M count=16
  sudo chmod 600 /swapfile
  sudo mkswap /swapfile
  sudo swapon /swapfile
  echo '/swapfile swap swap defaults 0 0' | sudo tee -a /etc/fstab
  EOF

  tags = {
    Name = "${var.common_info.env}-${var.common_info.service_name}-bastion-server"
  }
}
```

### 결과 확인

![image.png](https://github.com/INU-Capstone-ZEUS/inu-capstone-zeus.github.io/blob/master/assets/images/report/_7_report/image%206.png?raw=true)

## 도메인 구매 및 적용

### 가비아에서 도메인 구매

 EC2로 서버를 열어서 사용하다 보면, EC2에서 기본으로 제공하는 주소가 너무 길어서 불편함을 느낄 수밖에 없다. EC2의 퍼브릭 IP로 서비스를 배포함에 있어서 사용하는 것은 아무래도 무리가 있다. 따라서 가비아 사이트에서 도메인을 구매하도록 한다. 

[https://www.gabia.com/](https://www.gabia.com/)

![image.png](https://github.com/INU-Capstone-ZEUS/inu-capstone-zeus.github.io/blob/master/assets/images/report/_7_report/image%207.png?raw=true)

원하는 도메인을 선택하고 구매할 수 있고 .site 도메인을 선택하여 진행하였다. 

### Route 53에서 도메인 적용

 Route 53 AWS에서 제공하는 DNS 서비스이다. 이를 통해 사용자는 인터넷 도메인 이름을 웹 서버나 다른 AWS 리소스의 IP 주소와 매핑할 수 있다. 

Route 53에 EC2 서버를 연결하여 도메인을 사용할 것이다.

Route 53 대시보드에 접속해서 호스팅 영역을 생성한다. 그리고 ec2 서버 public ip를 연결하는 새 레코드를 생성한다. 

그 후 가비아 네임 서버에 ns 레코드 영역 값을 입력한다. 

ns 레코드 영역은 route 53에서 확인 가능하다. 

![image.png](https://github.com/INU-Capstone-ZEUS/inu-capstone-zeus.github.io/blob/master/assets/images/report/_7_report/image%208.png?raw=true)

 가비아의 네임서버를 변경해 주었기 때문에, 해당 도메인으로 모든 DNS 쿼리는 Route 53으로 전달된다. 

그리고 Route 53에 설정한 A 레코드에 의해 EC2의 IP 주소로 사용자의 트래픽이 라우팅 되며, 정상적으로 서비스를 이용할 수 있게 되었다. www.jeus.site로도 jeus.site로도 잘 전달이 된다.

## Nginx 웹 서버와 Certbot

Nginx는 정적 파일(HTML, CSS, JavaScript, 이미지 등)을 서빙하는데 효과적인 오픈소스이다. 

Nginx는 또한 리버스 프록시 서버로 사용할 수 있다. 리액트로 들어온 클라이언트의 요청을 다른 서버 Fast api 서버나 Node js 서버로 전달하고 다시 클라이언트에게 전달하는 역할을 한다. 

또 SSL/TLS 프로토콜을 지원하여 HTTP/HTTPS 들어오는 접근을 인증서로 안전하게 처리할 수 있다. 

따라서 우리는 Nginx 웹 서버를 사용하여 React 앱을 호스팅할 것이며 동시에 Certbot을 사용하여 인증서를 발급받고 사용할 것이다. 

Certbot을 사용하면 명령어 한 줄로 SSL 인증서를 발급받을 수 있는데. Let's Encrypt를 사용해서 그 과정을 구현한다. 

Let's Encrypt는 ACME(Automatic Certificate Management Environment) 프로토콜을 사용하여 인증서를 발급하는데, Certbot은 이 프로토콜을 구현한 클라이언트이다.

Let's Encrypt 인증서는 90일 동안 유효한데, Certbot은 인증서 갱신을 자동화하여 만료 전에 인증서를 갱신할 수 있다. 이로 인해 서버 관리자는 인증서 만료를 걱정하지 않고 웹사이트를 운영할 수 있다.

### 구현

Nginx와 Certbot을 Docker-compose를 이용하여 하나의 Container로 동시에 배포한다. 

HTTP와 HTTPS를 지원하기 위해 80번 PORT와 443 PORT를 오픈하며 volumes를 통해 EC2의 설정 파일들을 nginx 내부와 연동시킨다. 

예를 들어, "./data/nginx:/etc/nginx/conf.d"로 볼륨이 설정되면, "./data/nginx" 폴더 안에 파일들이 nginx 컨테이너 내부의 "/etc/nginx/conf.d"로 복사된다. 

먼저 다음과 같이 nginx 설정에 사용되는 conf 파일을 작성한다. 

```python
server {
    listen 80;
    server_name jeus.site www.jeus.site;
    server_tokens off;

    location /.well-known/acme-challenge/ {
        root /var/www/certbot;
    }

    location / {
        return 301 http://$host$request_uri;  # 301 Redirect to HTTP
    }
}

# SSL 설정은 주석 처리 또는 삭제
# server {
#     listen 443 ssl;
#     server_name jeus.site www.jeus.site;
#
#     ssl_certificate /etc/letsencrypt/live/jeus.site/fullchain.pem;
#     ssl_certificate_key /etc/letsencrypt/live/jeus.site/privkey.pem;
#
#     location / {
#         proxy_pass  http://jeus.site:8000;
#         proxy_set_header    Host                $http_host;
#         proxy_set_header    X-Real-IP           $remote_addr;
#         proxy_set_header    X-Forwarded-For     $proxy_add_x_forwarded_for;
#     }
# }
```

그 후 docker-compose.yaml를 작성한 후 docker compose up -d 명령어를 실행한다

```python
services:
  nginx:
    image: nginx:latest
    container_name: nginx
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./data/nginx:/etc/nginx/conf.d
      - ./data/certbot/conf:/etc/letsencrypt
      - ./data/certbot/www:/var/www/certbot
    depends_on:
      - certbot

  certbot:
    image: certbot/certbot
    volumes:
      - ./data/certbot/conf:/etc/letsencrypt
      - ./data/certbot/www:/var/www/certbot
```

그 후 curl을 통해 확인한다. 

![image.png](https://github.com/INU-Capstone-ZEUS/inu-capstone-zeus.github.io/blob/master/assets/images/report/_7_report/image%209.png?raw=true)

301으로 rebound가 오는 것을 확인 가능하다. 잘 가지는 것을 확인 가능하다. 

그리고 다음 명령어를 한번 더 실행해 인증서를 생성한다. 

```python
docker-compose run --rm certbot certonly --webroot --webroot-path=/var/www/certbot -d jeus.site -d www.jeus.site
```

```python
server {
    listen 80;
    server_name jeus.site www.jeus.site;
    server_tokens off;

    location /.well-known/acme-challenge/ {
        root /var/www/certbot;
    }

    location / {
        return 301 https://$host$request_uri;
    }
}

server {
    listen 443 ssl;
    server_name jeus.site www.jeus.site;
    server_tokens off;

    ssl_certificate /etc/letsencrypt/live/jeus.site/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/jeus.site/privkey.pem;

    location / {
        proxy_pass  http://jeus.site:8000;
        proxy_set_header    Host                $http_host;
        proxy_set_header    X-Real-IP           $remote_addr;
        proxy_set_header    X-Forwarded-For     $proxy_add_x_forwarded_for;
    }
}

```

그 다음 docker compose down 한 다음 다시 docker compose up -d를 하여 background로 certbot과 nginx를 실행한다. 

### 최종 결과

proxy_pass에 react app의 port를 지정해서 서빙해야 하지만 현재 아직 react 개발이 끝나지 않았기에 nginx 서버를 간단하게 8000번으로 띄워 테스트를 진행해보았다.

2개의 nginx server가 띄워져있음을 확인 가능하다. 하나는 react 대용이고 하나는 우리가 지금까지 구현한 웹 서버이다. curl로도 웹 브라우저 접속으로도 정상 작동하는 것을 확인 가능하다. 

또한 인증서도 정상 작동한다. 

![image.png](https://github.com/INU-Capstone-ZEUS/inu-capstone-zeus.github.io/blob/master/assets/images/report/_7_report/image%2010.png?raw=true)

---

## **FastAPI를 사용한 서버 구축**

작성했었던 크롤링 코드와 geminiAPI를 사용한 분석 코드를 합쳐서 하나의 라우터로 구성함.

```jsx
from fastapi import APIRouter
from pydantic import BaseModel
from typing import Dict, Any, List
from .crawl_news import crawl_news, CrawlError 
from .analyze_news import analyze_news
from fastapi import HTTPException

router = APIRouter()

# Gemini 분석 요청 
class AnalysisReqDTO(BaseModel):
    evaluation: str
    reason: str
    summary: str

# Gemini 분석 응답
class AnalysisResDTO(BaseModel):
    evaluation: str
    reason: str
    summary: str
    link: str

# 전체 요청
class CrawlAndAnalyzeRequest(BaseModel):
    company_code: str
    page: int
    company_name: str

# 전체 응답
class CrawlAndAnalyzeResponse(BaseModel):
    status: str
    total_articles: int 
    analysis: List[AnalysisResDTO]

@router.post("/crawl-and-analyze", response_model=CrawlAndAnalyzeResponse)
async def crawl_and_analyze(request: CrawlAndAnalyzeRequest) -> CrawlAndAnalyzeResponse:
    company_code = request.company_code
    page = request.page
    company_name = request.company_name

    # 크롤링 단계
    try:
        articles = crawl_news(company_code, page)
    except CrawlError as e:  # CrawlError만 처리
        raise HTTPException(status_code=400, detail=f"Crawling error: {e.message}")

        # return CrawlAndAnalyzeResponse(
        #     status="failed",
        #     total_articles=0,
        #     analysis=[],
        #     error_message=e.message
        # )
    except Exception as e:
        # 예기치 않은 에러 처리
        raise HTTPException(status_code=400, detail=f"Crawling error: {e.message}")

        # return CrawlAndAnalyzeResponse(
        #     status="failed",
        #     total_articles=0,
        #     analysis=[],
        #     error_message=f"Unexpected error: {str(e)}"
        # )

    # 분석 단계
    try:
        analyzed_articles = analyze_news(articles, company_name)
    except Exception as e:
        # Gemini API 요청 제한으로 인해 발생하는 에러 처리
        raise HTTPException(status_code=400, detail=f"Gemini API error: {e.message}")
        # return CrawlAndAnalyzeResponse(
        #     status="failed",
        #     total_articles=0,
        #     analysis=[],
        #     error_message=f"Gemini API error: {str(e)}"
        # )

    # 분석 결과를 DTO로 변환
    analysis_dto = [AnalysisResDTO(**article) for article in analyzed_articles]

    # 응답 데이터 생성
    return CrawlAndAnalyzeResponse(
        status="success",
        total_articles=len(analysis_dto),
        analysis=analysis_dto
    )

```

### **서버 배포**

FastAPI 서버 코드를 Docker image로 만든 뒤, docker hub에 push했음.

또한 Docker hub에 올린 이미지를 Ec2에서 pull한 뒤 실행시켰음.

![image.png](https://github.com/INU-Capstone-ZEUS/inu-capstone-zeus.github.io/blob/master/assets/images/report/_7_report/image%2011.png?raw=true)



---

If you like TeXt, don't forget to give me a star. :star2:

[![Star This Project](https://img.shields.io/github/stars/kitian616/jekyll-TeXt-theme.svg?label=Stars&style=social)](https://github.com/kitian616/jekyll-TeXt-theme/)
